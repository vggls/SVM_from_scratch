{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this repo we focus on the **SMO algorithm** (see \"summary.pdf\" Step5).\n",
    "\n",
    "It is one of the most well-known algorithms for **training Support Vector Machines**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SMO works in an iterative manner. At first the values of a and b are initialized. In every iteration we select two indices i, j\n",
    "and solve the dual problem (\"summary.pdf\" Step4) by fixing all a's for indices diffirent to i and j. \n",
    "An iterative step for a selected pair of indices i,j is described in the \"**Step**\" function below.\n",
    "\n",
    "**Remark** In this repo we choose the **iteration step** indices as suggested in well-known paper of John Platt \"Sequential Minimal Optimization A Fast Algorithm for training Support Vector Machines\" in pages 8-9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We develop two variations based on the type of boundary we want to get; either **linear** or **gaussian kernel** boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMO():\n",
    "    def __init__(self, X,y,steps,C, kernel = None, sigma = None ) :\n",
    "        \"\"\"\n",
    "        X : is an np.array matrix where each row corresponds to a dataset point\n",
    "        y : is an np.array vector with the labels of the datapoints\n",
    "        steps : describes the number of iterations in the SMO algorithm\n",
    "        C : is the optimal margin's hyperparameter that controls the width of the margin area and the number of misclassifications\n",
    "        kernel : if None then we get the parameters of the Optimal Margin Linear Boundary\n",
    "                 if not None then we get the parameters of the Optimal Margin Gaussian Kernel Boundary\n",
    "        sigma : the hyperparameter of the Gaussian kernel\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.steps = steps\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.sigma = sigma\n",
    "        if self.kernel != None and self.sigma == None :\n",
    "            print('Invalid arguments! Either remove the kernel attribute or insert the kernel sigma hyperparameter.')\n",
    "    \n",
    "    def Gauss(self, t, x):\n",
    "        \"\"\"\n",
    "        t : is a dataset vector in an np.array form\n",
    "        x : is either a dataset vector or a bunch of vectors\n",
    "        The output ie either a number or a vector\n",
    "        \"\"\"\n",
    "        if self.sigma == None :\n",
    "            return 'no sigma kernel hyperparameter was given as an attribute'\n",
    "        else :\n",
    "            if t.size == x.size : \n",
    "                return 1/np.exp( np.sum((t-x)**2) / (2*self.sigma**2) ) #number\n",
    "            else : #else in case x is the bunch of all datapoints\n",
    "                res = np.array([])\n",
    "                for j in range(x.shape[0]) :\n",
    "                    res = np.append(res, 1/np.exp( np.sum((t-x[j])**2) / (2*self.sigma**2) ))\n",
    "                return res #vector\n",
    "\n",
    "    def Bndry(self,t,a,b):\n",
    "        \"\"\"\n",
    "        t : is either an 1-dim np.array vector OR a 2-dim np.array vector OR a 2-dim np.array matrix\n",
    "        Computes the boundary function at point t (see a and b dependent formula in summary notes)\n",
    "        \"\"\"\n",
    "        if self.kernel == None :\n",
    "            if t.ndim == 1 :\n",
    "                return np.sum(a*self.y*(self.X@t)) + b #number\n",
    "            if t.ndim == 2:\n",
    "                if t.size == self.X[0].size : # ie if t is a vector\n",
    "                    return np.sum(a*self.y*(self.X@(t.T))) + b #number\n",
    "                else : # ie if t is a matrix\n",
    "                    res = np.array([])\n",
    "                    for j in range(t.shape[0]):\n",
    "                        res = np.append( res, np.sum(a*self.y*(self.X@t[j])) + b )\n",
    "                    return res #vector\n",
    "        elif self.kernel != None :\n",
    "            if t.ndim == 1 :\n",
    "                return np.sum(a*self.y*self.Gauss(t,self.X)) + b\n",
    "            if t.ndim == 2 :\n",
    "                if t.size == self.X[0].size :\n",
    "                    return np.sum(a*self.y*(self.Gauss(t,self.X))) + b\n",
    "                else :\n",
    "                    res = np.array([])\n",
    "                    for j in range(t.shape[0]):\n",
    "                        res = np.append(res, np.sum(a*self.y*(self.Gauss(t[j],self.X))) + b)\n",
    "                    return res\n",
    "        \n",
    "    \n",
    "    def Step(self,i,j,a,b):\n",
    "        \"\"\"\n",
    "        i, j : are dataset point indices\n",
    "        Outputs the optimized a and b after an SMO iteration\n",
    "        \"\"\"\n",
    "\n",
    "        if self.kernel==None :\n",
    "            delta = self.y[i]*((self.Bndry(self.X[j,:],a,b)-self.y[j]) - (self.Bndry(self.X[i,:],a,b)-self.y[i]))\n",
    "            Chi = self.X[i,:].dot(self.X[i,:]) + self.X[j,:].dot(self.X[j,:]) - 2*self.X[i,:].dot(self.X[j,:])\n",
    "        else :\n",
    "            delta = self.y[i]*((self.Bndry(self.X[j,:],a,b)-self.y[j])-(self.Bndry(self.X[i,:],a,b)-self.y[i]))\n",
    "            Chi = self.Gauss(self.X[i,:],self.X[i,:]) + self.Gauss(self.X[j,:],self.X[j,:]) -2*self.Gauss(self.X[i,:],self.X[j,:]) \n",
    "\n",
    "        s = self.y[i]*self.y[j]\n",
    "        gamma = s*a[i]+a[j]\n",
    "\n",
    "        if s == 1:\n",
    "            L = max(0,gamma-C); H = min(gamma,C)\n",
    "        else:\n",
    "            L = max(0,-gamma); H = min(C,C-gamma)\n",
    "\n",
    "        if Chi > 0:\n",
    "            a[i] = min(max(a[i]+delta/Chi,L),H)\n",
    "        elif delta > 0:\n",
    "            a[i] = L\n",
    "        else:\n",
    "            a[i] = H\n",
    "\n",
    "        a[j] = gamma-s*a[i]\n",
    "\n",
    "        if self.kernel==None :\n",
    "            b = b-1/2*(self.Bndry(self.X[i,:],a,b)-self.y[i]+self.Bndry(self.X[j,:],a,b)-self.y[j])\n",
    "        else :\n",
    "            b = b-1/2*(self.Bndry(self.X[i,:],a,b)-self.y[i]+self.Bndry(self.X[j,:],a,b)-self.y[j])\n",
    "\n",
    "        return a,b\n",
    "\n",
    "    \n",
    "    \n",
    "    def Smo(self):\n",
    "        \"\"\"\n",
    "        Outputs the optimal support vectors a and the optimal b.\n",
    "        These two parameters characterize the desired optimal margin boundary in both linear and kernelized cases\n",
    "        \"\"\"\n",
    "        a = np.zeros(self.X.shape[0])\n",
    "        b = 0\n",
    "        kkt = np.ones(a.size)\n",
    "        count = 0\n",
    "        while (count < self.steps):\n",
    "            for i in range(a.size): \n",
    "                H_i = self.Bndry(X[i,:],a,b)  \n",
    "                kkt[i] = (self.C-a[i])*max(0,1-self.y[i]*H_i) + a[i]*max(0,self.y[i]*H_i-1)\n",
    "                if kkt[i]>0:\n",
    "                    count += 1\n",
    "                    # take an array of all possible indices, erase all that aren't margin vectors and erase i from the list too\n",
    "                    k = np.arange(self.X.shape[0]) \n",
    "                    t = k[(a>0) & (a<self.C)]\n",
    "                    t = np.delete(t,np.where( t == i))\n",
    "                    # if there are indices which fullfill this restriction pick one of them\n",
    "                    if t.size > 0: \n",
    "                        j = np.random.choice(t)\n",
    "                        temp = self.Step(i,j,a,b)\n",
    "                        betha = temp[0]\n",
    "                        b = temp[1]\n",
    "                    # else just pick a random index of all possible but i\n",
    "                    else:\n",
    "                        k = np.delete(k,np.where(k == i))\n",
    "                        j = np.random.choice(k)\n",
    "                        temp = self.Step(i,j,a,b)\n",
    "                        betha = temp[0]\n",
    "                        b = temp[1]\n",
    "            # check if all  KKT_i are zero, if so stop\n",
    "            if np.array_equal(kkt, np.zeros(kkt.size)):\n",
    "                break\n",
    "\n",
    "        med = np.zeros(self.X.shape[0])\n",
    "        supcount = 0\n",
    "        for i in range(self.X.shape[0]):\n",
    "            if a[i] > 0:\n",
    "                med[i] = self.Bndry(self.X[i,:],a,b) - self.y[i]\n",
    "                supcount += 1 \n",
    "        averg = np.sum(med)/supcount\n",
    "        b = b - averg\n",
    "\n",
    "        return a,b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
